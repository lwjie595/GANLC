# -*- coding: utf-8 -*-
"""Ops.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LqN0T0qUtgWDWJC6Oj9Ns1omvW2b4c21
"""
from matplotlib.animation import ArtistAnimation
from matplotlib.animation import PillowWriter
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import pdb
import torch.nn.functional as F
import numpy as np, cv2 as cv, scipy
from scipy import signal
import collections

import imageio


# Preprocessing functions
def preprocess(image):
    # Converts image range from [0,1] to [-1,1]
    return image * 2 - 1


def deprocess(image):
    # [-1,1] --> [0,1]
    return (image + 1) / 2


def preprocessLr(image):
    identity = nn.Identity()
    return identity(image)


def deprocessLr(image):
    identity = nn.Identity()
    return identity(image)


# CNN layers
def conv2_tran(input_channels, kernel=3, output_channel=64, stride=1, use_bias=True, output_padding=0):
    padding = int((kernel - 1) / 2)

    if use_bias:
        trans_conv = nn.ConvTranspose2d(input_channels, output_channel, kernel, stride, padding=padding, bias=True
                                        , output_padding=output_padding)
    else:
        trans_conv = nn.ConvTranspose2d(input_channels, output_channel, kernel, stride, padding=padding, bias=False
                                        , output_padding=output_padding)
    return trans_conv


def conv2(batch_input, kernel=3, output_channels=64, stride=1, use_bias=True):
    padding = int((kernel - 1) / 2)
    if use_bias:
        conv = nn.Conv2d(batch_input, output_channels, kernel, stride, padding=padding, bias=True)
    else:
        conv = nn.Conv2d(batch_input, output_channels, kernel, stride, padding=padding, bias=False)
    return conv


def prelu(inputs):
    prelu = nn.PReLU(inputs.shape[1], 0)
    return prelu


def lrelu(alphas):
    return nn.LeakyReLU(negative_slope=alphas)


def batchnorm(inputs, is_training):
    batchn = nn.BatchNorm2d(inputs, eps=0.001)
    return batchn


def maxpool(kernel_size=(2, 2)):
    pool = nn.MaxPool2d(kernel_size)
    return pool


def denselayer(inputs, output_size):
    fc = nn.Linear(inputs, output_size)
    torch.nn.init.xavier_uniform_(fc.weight)
    return fc


# Different processing functions

def pixelshuffle(inputs, scale=2):
    shuffle = nn.PixelShuffel(2)
    return shuffle


def upscale_four(inputs):
    upsample = nn.Upsample(scale_factor=4, mode="bilinear")
    return upsample(inputs)


def bicubic_four(inputs):
    upsample = nn.Upsample(scale_factor=4, mode="bicubic")
    return upsample(inputs)


def phaseShift(inputs, scale, shape_1, shape_2):
    X = torch.reshape(inputs, shape_1)
    X = torch.transpose(X, [0, 1, 2, 3, 4])
    return torch.reshape(X, shape_2)


def random_flip_batch(input, decision):
    identity = torch.identity()
    f1 = identity(input)
    f2 = torch.flip(input, dim=3)
    return torch.where(torch.less(decision, 0.5), f2, f1)


def random_flip(input, decision):
    identity = torch.identity()
    f1 = identity(input)
    f2 = torch.flip(input, dim=3)
    return torch.where(torch.less(decision, 0.5), f2, f1)


# computing the benchmark psnr

def compute_psnr(ref, target):
    ref = ref.float()
    target = target.float()
    diff = target - ref
    sqr = torch.multiply(diff, diff)
    err = sqr.sum()
    v = diff.shape[0] * diff.shape[1] * diff.shape[2] * diff.shape[3]
    mse = err / v
    psnr = 10. * (torch.log(255. * 255. / mse) / torch.log(torch.tensor(10.)))
    return psnr


# Defining the VGG model for layer loss

class VGG19(nn.Module):
    def __init__(self):
        super(VGG19, self).__init__()
        self.Conv1_1 = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU())
        self.Conv1_2 = nn.Sequential(nn.Conv2d(64, 64, 3, padding=1), nn.ReLU())
        self.pool1 = nn.MaxPool2d((2, 2), stride=2)
        self.Conv2_1 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1), nn.ReLU())
        self.Conv2_2 = nn.Sequential(nn.Conv2d(128, 128, 3, padding=1), nn.ReLU())
        self.pool2 = nn.MaxPool2d((2, 2), stride=2)
        self.Conv3_1 = nn.Sequential(nn.Conv2d(128, 256, padding=1), nn.ReLU())
        self.Conv3_2 = nn.Sequential(nn.Conv2d(256, 256, padding=1), nn.ReLU())
        self.Conv3_3 = nn.Sequential(nn.Conv2d(256, 256, padding=1), nn.ReLU())
        self.Conv3_4 = nn.Sequential(nn.Conv2d(256, 256, padding=1), nn.ReLU())
        self.pool3 = nn.MaxPool2d((2, 2), stride=2)
        self.Conv4_1 = nn.Sequential(nn.Conv2d(256, 512, padding=1), nn.ReLU())
        self.Conv4_2 = nn.Sequential(nn.Conv2d(512, 512, padding=1), nn.ReLU())
        self.Conv4_3 = nn.Sequential(nn.Conv2d(512, 512, padding=1), nn.ReLU())
        self.Conv4_4 = nn.Sequential(nn.Conv2d(512, 512, padding=1), nn.ReLU())
        self.pool4 = nn.MaxPool2d((2, 2), stride=2)
        self.Conv5_1 = nn.Sequential(nn.Conv2d(512, 512, padding=1), nn.ReLU())
        self.Conv5_2 = nn.Sequential(nn.Conv2d(512, 512, padding=1), nn.ReLU())
        self.Conv5_3 = nn.Sequential(nn.Conv2d(512, 512, padding=1), nn.ReLU())
        self.Conv5_4 = nn.Sequential(nn.Conv2d(512, 512, padding=1), nn.ReLU())
        self.pool5 = nn.MaxPool2d((2, 2), stride=2)
        self.end_points = {}

    def forward(self, x):
        x = self.Conv1_1(x)
        self.end_points["vgg_19/conv1_1"] = x
        x = self.Conv1_2(x)
        self.end_points["vgg_19/conv1_2"] = x
        x = self.pool1(x)
        self.end_points["vgg_19/pool1"] = x
        x = self.Conv2_1(x)
        self.end_points["vgg_19/conv2_1"] = x
        x = self.Conv2_2(x)
        self.end_points["vgg_19/conv2_2"] = x
        x = self.pool2(x)
        self.end_points["vgg_19/pool2"] = x
        x = self.Conv3_1(x)
        self.end_points["vgg_19/conv3_1"] = x
        x = self.Conv3_2(x)
        self.end_points["vgg_19/conv3_2"] = x
        x = self.Conv3_3(x)
        self.end_points["vgg_19/conv3_3"] = x
        x = self.Conv3_4(x)
        self.end_points["vgg_19/conv3_4"] = x
        x = self.pool3(x)
        self.end_points["vgg_19/pool3"] = x
        x = self.Conv4_1(x)
        self.end_points["vgg_19/conv4_1"] = x
        x = self.Conv4_2(x)
        self.end_points["vgg_19/conv4_2"] = x
        x = self.Conv4_3(x)
        self.end_points["vgg_19/conv4_3"] = x
        x = self.Conv4_4(x)
        self.end_points["vgg_19/conv4_4"] = x
        x = self.pool4(x)
        self.end_points["vgg_19/pool4"] = x
        x = self.Conv5_1(x)
        self.end_points["vgg_19/conv5_1"] = x
        x = self.Conv5_2(x)
        self.end_points["vgg_19/conv5_2"] = x
        x = self.Conv5_3(x)
        self.end_points["vgg_19/conv5_3"] = x
        x = self.Conv5_4(x)
        self.end_points["vgg_19/conv5_4"] = x
        output = self.pool5(x)
        self.end_points["vgg_19/pool5"] = output
        return output, self.end_points


# Upsample functions

def gaussian_2dkernel(size=5, sig=1.):
    """
    Returns a 2D Gaussian kernel array with side length size and a sigma of sig
    """
    gkern1d = signal.gaussian(size, std=sig).reshape(size, 1)
    gkern2d = np.outer(gkern1d, gkern1d)
    return (gkern2d / gkern2d.sum())


# Loading checkpoint
def load_ckpt(checkpoint, model):
    return model.load_state_dict(torch.load(checkpoint))


# Functions for saving images and gifs

def save_as_gif(tensor, filepath):
    img = tensor.float().numpy() * 255.
    images = np.transpose(img.astype(np.uint8), (0, 2, 3, 1))
    imageio.mimsave(filepath, images)


def save_img(out_path, img):
    img = np.clip(img * 255.0, 0, 255).astype(np.uint8)
    cv.imwrite(out_path, img[:, :, ::-1])

def _rgb2ycbcr(img, maxVal=255):
##### color space transform, originally from https://github.com/yhjo09/VSR-DUF #####
    O = np.array([[16],
                  [128],
                  [128]])
    T = np.array([[0.256788235294118, 0.504129411764706, 0.097905882352941],
                  [-0.148223529411765, -0.290992156862745, 0.439215686274510],
                  [0.439215686274510, -0.367788235294118, -0.071427450980392]])

    if maxVal == 1:
        O = O / 255.0

    t = np.reshape(img, (img.shape[0]*img.shape[1], img.shape[2]))
    t = np.dot(t, np.transpose(T))
    t[:, 0] += O[0]
    t[:, 1] += O[1]
    t[:, 2] += O[2]
    ycbcr = np.reshape(t, [img.shape[0], img.shape[1], img.shape[2]])

    return ycbcr

def to_uint8(x, vmin, vmax):
##### color space transform, originally from https://github.com/yhjo09/VSR-DUF #####
    x = x.astype('float32')
    x = (x-vmin)/(vmax-vmin)*255 # 0~255
    return np.clip(np.round(x), 0, 255)


def cut_image(image, vmin, vmax):
    # image = np.maximum(image, vmin)
    # image = np.minimum(image, vmax)

    return image

def psnr(img_true, img_pred):
    ##### PSNR with color space transform, originally from https://github.com/yhjo09/VSR-DUF #####
    Y_true = _rgb2ycbcr(to_uint8(img_true, 0, 255), 255)[:, :, 0]
    Y_pred = _rgb2ycbcr(to_uint8(img_pred, 0, 255), 255)[:, :, 0]
    diff = Y_true - Y_pred
    rmse = np.sqrt(np.mean(np.power(diff, 2)))
    return 10 * np.log10(255. / rmse)

from skimage.measure import compare_ssim
def ssim(img_true, img_pred):  ##### SSIM #####
    Y_true = _rgb2ycbcr(to_uint8(img_true, 0, 255), 255)[:, :, 0]
    Y_pred = _rgb2ycbcr(to_uint8(img_pred, 0, 255), 255)[:, :, 0]
    return compare_ssim(Y_true, Y_pred, data_range=Y_pred.max() - Y_pred.min())


